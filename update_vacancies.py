import requests
import json
from datetime import datetime, timedelta
import time
from typing import List, Dict, Optional, Set

# API HH.ru
BASE_URL = "https://api.hh.ru/vacancies"

# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
HEADERS = {
    'User-Agent': 'VacancyParser/2.0 (contact@example.com)'
}

# –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
REQUEST_DELAY = 0.3

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
SEARCH_KEYWORDS = [
    '—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä',
    '—Å–∏—Å–∞–¥–º–∏–Ω',
    'system administrator'
]


def get_vacancies_with_pagination_fix(keyword: str, region_id: str = '1') -> tuple[List[Dict], Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å –æ–±—Ö–æ–¥–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç per_page=50 –∫–∞–∫ –Ω–∞ —Å–∞–π—Ç–µ –∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    """
    print(f"\n{'='*60}")
    print(f"üîç –ü–æ–∏—Å–∫: '{keyword}' –≤ –ú–æ—Å–∫–≤–µ")
    print(f"{'='*60}")
    
    all_vacancies = []
    stats = {
        'found': 0,
        'collected': 0,
        'method': 'standard'
    }
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥ —Å per_page=50
    params = {
        'text': keyword,
        'area': region_id,
        'search_field': 'name',
        'per_page': 50,  # –ö–∞–∫ –Ω–∞ —Å–∞–π—Ç–µ!
        'page': 0
    }
    
    # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    try:
        response = requests.get(BASE_URL, params=params, headers=HEADERS, timeout=30)
        if response.status_code == 200:
            data = response.json()
            stats['found'] = data.get('found', 0)
            total_pages = data.get('pages', 0)
            
            print(f"–ù–∞–π–¥–µ–Ω–æ: {stats['found']} –≤–∞–∫–∞–Ω—Å–∏–π")
            print(f"–°—Ç—Ä–∞–Ω–∏—Ü: {total_pages}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
            max_accessible = 20 * 50  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –ª–∏–º–∏—Ç –≤ 20 —Å—Ç—Ä–∞–Ω–∏—Ü
            if stats['found'] > max_accessible:
                print(f"‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: {stats['found']} > {max_accessible}")
                stats['method'] = 'segmented'
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –¥–∞—Ç–∞–º
                all_vacancies = get_with_date_segmentation(keyword, region_id)
                stats['collected'] = len(all_vacancies)
            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–±–æ—Ä
                all_vacancies = collect_all_pages(params, total_pages)
                stats['collected'] = len(all_vacancies)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ: {stats['collected']} –∏–∑ {stats['found']} ({stats['method']})")
    return all_vacancies, stats


def collect_all_pages(base_params: Dict, total_pages: int) -> List[Dict]:
    """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    all_items = []
    
    for page in range(min(total_pages, 20)):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 20 —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
        params = base_params.copy()
        params['page'] = page
        
        try:
            response = requests.get(BASE_URL, params=params, headers=HEADERS, timeout=30)
            if response.status_code == 200:
                data = response.json()
                items = data.get('items', [])
                
                if not items:
                    print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –ø—É—Å—Ç–∞—è, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º")
                    break
                
                all_items.extend(items)
                print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: {len(items)} –≤–∞–∫–∞–Ω—Å–∏–π (–≤—Å–µ–≥–æ: {len(all_items)})")
                
                time.sleep(REQUEST_DELAY)
            else:
                print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –æ—à–∏–±–∫–∞ {response.status_code}")
                break
                
        except Exception as e:
            print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –æ—à–∏–±–∫–∞ {e}")
            break
    
    return all_items


def get_with_date_segmentation(keyword: str, region_id: str) -> List[Dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π –ø–æ –¥–∞—Ç–∞–º"""
    print("\nüìÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –¥–∞—Ç–∞–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
    
    all_vacancies = []
    unique_ids = set()
    
    # –°–µ–≥–º–µ–Ω—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π)
    segments = [
        {'days': 1, 'name': '–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞'},
        {'days': 3, 'name': '–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è'},
        {'days': 7, 'name': '–ó–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é'},
        {'days': 14, 'name': '–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –Ω–µ–¥–µ–ª–∏'},
        {'days': 30, 'name': '–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü'}
    ]
    
    end_date = datetime.now()
    
    for i, segment in enumerate(segments):
        # –î–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –Ω–∞—á–∏–Ω–∞–µ–º —Å —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞
        if i == 0:
            date_from = end_date - timedelta(days=segment['days'])
        else:
            # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö - —Å –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
            date_from = end_date - timedelta(days=segment['days'])
            date_to_prev = end_date - timedelta(days=segments[i-1]['days'])
            date_from = date_to_prev
        
        date_to = end_date if i == 0 else end_date - timedelta(days=segments[i-1]['days'])
        
        print(f"\nüîç {segment['name']}")
        print(f"   –° {date_from.strftime('%Y-%m-%d')} –ø–æ {date_to.strftime('%Y-%m-%d')}")
        
        params = {
            'text': keyword,
            'area': region_id,
            'search_field': 'name',
            'date_from': date_from.strftime('%Y-%m-%d'),
            'date_to': date_to.strftime('%Y-%m-%d'),
            'per_page': 50,
            'page': 0
        }
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞
        segment_vacancies = []
        page = 0
        
        while True:
            params['page'] = page
            
            try:
                response = requests.get(BASE_URL, params=params, headers=HEADERS, timeout=30)
                if response.status_code == 200:
                    data = response.json()
                    
                    if page == 0:
                        found_in_segment = data.get('found', 0)
                        print(f"   –ù–∞–π–¥–µ–Ω–æ –≤ —Å–µ–≥–º–µ–Ω—Ç–µ: {found_in_segment}")
                    
                    items = data.get('items', [])
                    if not items:
                        break
                    
                    segment_vacancies.extend(items)
                    
                    if page >= data.get('pages', 0) - 1:
                        break
                    
                    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –≥–ª—É–±–∏–Ω—É
                    if page >= 19:
                        print(f"   –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü")
                        break
                    
                    page += 1
                    time.sleep(REQUEST_DELAY)
                else:
                    break
            except Exception as e:
                print(f"   –û—à–∏–±–∫–∞: {e}")
                break
        
        # –î–æ–±–∞–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        new_count = 0
        for item in segment_vacancies:
            vacancy_id = item.get('id')
            if vacancy_id and vacancy_id not in unique_ids:
                unique_ids.add(vacancy_id)
                all_vacancies.append(item)
                new_count += 1
        
        print(f"   –î–æ–±–∞–≤–ª–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {new_count}")
        print(f"   –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ: {len(all_vacancies)}")
    
    return all_vacancies


def parse_vacancy(item: Dict) -> Dict:
    """–ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏"""
    vacancy = {
        'id': item.get('id', ''),
        'name': item.get('name', ''),
        'company': item.get('employer', {}).get('name', ''),
        'company_url': item.get('employer', {}).get('alternate_url', ''),
        'salary': '–Ω–µ —É–∫–∞–∑–∞–Ω–∞',
        'experience': item.get('experience', {}).get('name', ''),
        'schedule': item.get('schedule', {}).get('name', ''),
        'employment': item.get('employment', {}).get('name', ''),
        'area': item.get('area', {}).get('name', ''),
        'published_at': item.get('published_at', ''),
        'url': item.get('alternate_url', ''),
        'requirement': item.get('snippet', {}).get('requirement', ''),
        'responsibility': item.get('snippet', {}).get('responsibility', ''),
        'premium': item.get('premium', False),
        'has_test': item.get('has_test', False)
    }
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã
    if item.get('salary'):
        salary_data = item['salary']
        salary_from = salary_data.get('from')
        salary_to = salary_data.get('to')
        currency = salary_data.get('currency', 'RUR')
        gross = salary_data.get('gross', False)
        
        if salary_from and salary_to:
            vacancy['salary'] = f"–æ—Ç {salary_from:,} –¥–æ {salary_to:,} {currency}"
        elif salary_from:
            vacancy['salary'] = f"–æ—Ç {salary_from:,} {currency}"
        elif salary_to:
            vacancy['salary'] = f"–¥–æ {salary_to:,} {currency}"
            
        if gross:
            vacancy['salary'] += " (–¥–æ –≤—ã—á–µ—Ç–∞ –Ω–∞–ª–æ–≥–æ–≤)"
        else:
            vacancy['salary'] += " (–Ω–∞ —Ä—É–∫–∏)"
    
    return vacancy


def collect_all_vacancies() -> List[Dict]:
    """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –≤—Å–µ–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
    print("=" * 60)
    print("–°–ë–û–† –í–ê–ö–ê–ù–°–ò–ô –°–ò–°–¢–ï–ú–ù–´–• –ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–û–†–û–í –í –ú–û–°–ö–í–ï")
    print(f"–í—Ä–µ–º—è: {datetime.now()}")
    print("–ú–µ—Ç–æ–¥: –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π (—Å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)")
    print("=" * 60)
    
    all_vacancies = []
    unique_ids = set()
    total_stats = {
        'total_found': 0,
        'total_collected': 0,
        'by_keyword': {}
    }
    
    for keyword in SEARCH_KEYWORDS:
        vacancies, stats = get_vacancies_with_pagination_fix(keyword, '1')
        
        total_stats['by_keyword'][keyword] = stats
        total_stats['total_found'] += stats['found']
        
        # –î–æ–±–∞–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        new_count = 0
        for item in vacancies:
            vacancy_id = item.get('id')
            if vacancy_id and vacancy_id not in unique_ids:
                unique_ids.add(vacancy_id)
                vacancy = parse_vacancy(item)
                all_vacancies.append(vacancy)
                new_count += 1
        
        print(f"üìå –î–æ–±–∞–≤–ª–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {new_count}")
        print(f"üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(all_vacancies)}")
    
    total_stats['total_collected'] = len(all_vacancies)
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\n{'='*60}")
    print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print(f"{'='*60}")
    
    for keyword, stats in total_stats['by_keyword'].items():
        completeness = (stats['collected'] / stats['found'] * 100) if stats['found'] > 0 else 0
        print(f"'{keyword}':")
        print(f"  - –ù–∞–π–¥–µ–Ω–æ: {stats['found']}")
        print(f"  - –°–æ–±—Ä–∞–Ω–æ: {stats['collected']} ({completeness:.1f}%)")
        print(f"  - –ú–µ—Ç–æ–¥: {stats['method']}")
    
    print(f"\n–í–°–ï–ì–û —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {total_stats['total_collected']}")
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ
    try:
        all_vacancies.sort(key=lambda x: x.get('published_at', ''), reverse=True)
    except:
        pass
    
    return all_vacancies


def save_vacancies(vacancies: List[Dict], filename: str = 'hh_vacancies.json'):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ JSON —Ñ–∞–π–ª"""
    stats = {
        'total': len(vacancies),
        'with_salary': sum(1 for v in vacancies if v['salary'] != '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
        'companies': len(set(v['company'] for v in vacancies if v['company'])),
        'premium': sum(1 for v in vacancies if v.get('premium', False)),
        'with_test': sum(1 for v in vacancies if v.get('has_test', False))
    }
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥—Ä–∞—Ñ–∏–∫–∞–º
    schedules = {}
    for v in vacancies:
        schedule = v.get('schedule', '–ù–µ —É–∫–∞–∑–∞–Ω')
        schedules[schedule] = schedules.get(schedule, 0) + 1
    
    output = {
        'source': 'hh.ru',
        'search_keywords': SEARCH_KEYWORDS,
        'search_params': {
            'area': '–ú–æ—Å–∫–≤–∞',
            'area_id': '1',
            'search_field': '–í –Ω–∞–∑–≤–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏',
            'method': '–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π'
        },
        'updated': datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'),
        'statistics': stats,
        'schedule_distribution': schedules,
        'total_count': len(vacancies),
        'vacancies': vacancies
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –§–∞–π–ª {filename} —Å–æ–∑–¥–∞–Ω")
    print(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        vacancies = collect_all_vacancies()
        
        if vacancies:
            save_vacancies(vacancies)
            
            # –¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–π
            companies = {}
            for v in vacancies:
                company = v['company']
                if company:
                    companies[company] = companies.get(company, 0) + 1
            
            top_companies = sorted(companies.items(), key=lambda x: x[1], reverse=True)[:5]
            print("\nüè¢ –¢–æ–ø-5 –∫–æ–º–ø–∞–Ω–∏–π:")
            for company, count in top_companies:
                print(f"  - {company}: {count} –≤–∞–∫–∞–Ω—Å–∏–π")
        else:
            print("\n‚ùå –í–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
