#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å HeadHunter —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ—Ç–ª–∞–¥–∫–æ–π
"""

import json
import requests
from datetime import datetime
import time
import sys
import os

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
CONFIG = {
    'base_url': 'https://api.hh.ru/vacancies',
    'search_params': {
        'text': '–°–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä',
        'area': '113',  # –†–æ—Å—Å–∏—è
        'search_field': 'name',
        'order_by': 'publication_time',
        'period': '1',
        'per_page': '50',  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        'page': '0',
        'schedule': 'remote',
    },
    'headers': {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    },
    'output_file': 'hh_vacancies.json',
    'max_pages': 2  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
}

def format_salary(salary):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞—Ä–ø–ª–∞—Ç–µ"""
    if not salary:
        return '–ó–∞—Ä–ø–ª–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'
    
    parts = []
    if salary.get('from'):
        parts.append(f"–æ—Ç {salary['from']:,}".replace(',', ' '))
    if salary.get('to'):
        parts.append(f"–¥–æ {salary['to']:,}".replace(',', ' '))
    
    if parts:
        result = ' '.join(parts)
        currency = salary.get('currency', 'RUR')
        if currency == 'RUR':
            result += ' —Ä—É–±.'
        else:
            result += f' {currency}'
        return result
    
    return '–ó–∞—Ä–ø–ª–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'

def test_api_connection():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å API"""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å API HeadHunter...")
    try:
        response = requests.get(
            'https://api.hh.ru/vacancies',
            params={'text': 'test', 'per_page': '1'},
            headers=CONFIG['headers'],
            timeout=10
        )
        print(f"‚úÖ –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
        if response.status_code == 200:
            print("‚úÖ API –¥–æ—Å—Ç—É–ø–µ–Ω")
            return True
        else:
            print(f"‚ùå API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É: {response.text}")
            return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")
        return False

def fetch_vacancies(page=0):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    params = CONFIG['search_params'].copy()
    params['page'] = str(page)
    
    print(f"üì° –ó–∞–ø—Ä–æ—Å –∫ API, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page + 1}...")
    print(f"   URL: {CONFIG['base_url']}")
    print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {params}")
    
    try:
        response = requests.get(
            CONFIG['base_url'],
            params=params,
            headers=CONFIG['headers'],
            timeout=30
        )
        
        print(f"   –°—Ç–∞—Ç—É—Å: {response.status_code}")
        
        if response.status_code != 200:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {response.text}")
            return None
            
        return response.json()
        
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
        return None

def parse_vacancy(item):
    """–ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏"""
    return {
        'title': item['name'],
        'company': item['employer']['name'],
        'salary': format_salary(item.get('salary')),
        'publishDate': item['published_at'].split('T')[0],
        'url': item['alternate_url'],
        'experience': item.get('experience', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω'),
        'employment': item.get('employment', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
        'schedule': item.get('schedule', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω'),
        'area': item.get('area', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
    }

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å HeadHunter")
    print(f"üìÖ –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üîß –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")
    print(f"üìÅ –§–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {', '.join(os.listdir('.'))}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º API
    if not test_api_connection():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API")
        sys.exit(1)
    
    all_vacancies = []
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
    print("\nüìã –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π...")
    data = fetch_vacancies(0)
    
    if not data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–º–∏
        print("üìù –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–º–∏...")
        demo_data = {
            'source': 'hh.ru',
            'updated': datetime.now().isoformat() + 'Z',
            'total_found': 0,
            'vacancies_count': 0,
            'search_params': CONFIG['search_params'],
            'vacancies': [],
            'error': 'Failed to fetch data from API'
        }
        
        with open(CONFIG['output_file'], 'w', encoding='utf-8') as f:
            json.dump(demo_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª {CONFIG['output_file']} —Å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–º–∏")
        sys.exit(0)
    
    total_found = data.get('found', 0)
    pages = data.get('pages', 1)
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {total_found}")
    print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü: {pages}")
    
    # –ü–∞—Ä—Å–∏–º –≤–∞–∫–∞–Ω—Å–∏–∏
    for item in data.get('items', []):
        all_vacancies.append(parse_vacancy(item))
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    pages_to_load = min(pages, CONFIG['max_pages'])
    for page in range(1, pages_to_load):
        print(f"\nüìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page + 1}/{pages_to_load}...")
        time.sleep(0.5)
        
        data = fetch_vacancies(page)
        if data:
            for item in data.get('items', []):
                all_vacancies.append(parse_vacancy(item))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    all_vacancies.sort(key=lambda x: x['publishDate'], reverse=True)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = {
        'source': 'hh.ru',
        'updated': datetime.now().isoformat() + 'Z',
        'total_found': total_found,
        'vacancies_count': len(all_vacancies),
        'search_params': CONFIG['search_params'],
        'vacancies': all_vacancies
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª {CONFIG['output_file']}...")
    
    try:
        with open(CONFIG['output_file'], 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω
        if os.path.exists(CONFIG['output_file']):
            file_size = os.path.getsize(CONFIG['output_file'])
            print(f"‚úÖ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            print(f"üìè –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
            print(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(all_vacancies)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –≤–∞–∫–∞–Ω—Å–∏–∏
            if all_vacancies:
                print("\nüìå –ü–æ—Å–ª–µ–¥–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏:")
                for i, vac in enumerate(all_vacancies[:3], 1):
                    print(f"\n{i}. {vac['title']}")
                    print(f"   üíº {vac['company']}")
                    print(f"   üí∞ {vac['salary']}")
        else:
            print("‚ùå –§–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω!")
            sys.exit(1)
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
        sys.exit(1)
    
    print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    print(f"üïí –í—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()
