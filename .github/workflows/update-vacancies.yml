name: Update Vacancies

on:
  schedule:
    # –ó–∞–ø—É—Å–∫ –∫–∞–∂–¥—ã–π 1 —á–∞—Å–æ–≤
    - cron: '0 */1 * * *'
  workflow_dispatch: # –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫

jobs:
  update-vacancies:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests
          
      - name: Create enhanced vacancy collector script
        run: |
          cat > collect_vacancies.py << 'EOF'
          import requests
          import json
          import time
          from datetime import datetime
          from typing import List, Dict, Optional, Set
          import re
          import os
          
          # API HH.ru
          BASE_URL = "https://api.hh.ru/vacancies"
          
          # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
          HEADERS = {
              'User-Agent': 'VacancyAggregator/2.0 (https://gradelift.ru)'
          }
          
          # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
          REQUEST_DELAY = 0.3
          
          # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
          SEARCH_KEYWORDS = [
              '—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä',
              '—Å–∏—Å–∞–¥–º–∏–Ω',
              'system administrator'
          ]
          
          
          def get_vacancies_by_keyword(keyword: str) -> List[Dict]:
              """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –æ–¥–Ω–æ–º—É –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É"""
              print(f"\nüîç –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: '{keyword}'")
              
              params = {
                  'text': keyword,
                  'area': '113',              # –†–æ—Å—Å–∏—è
                  'schedule': 'remote',       # –£–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞
                  'search_field': 'name',     # –ò—Å–∫–∞—Ç—å –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
                  'per_page': '100',          # –ú–∞–∫—Å–∏–º—É–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
                  'page': '0'
              }
              
              all_vacancies = []
              page = 0
              total_pages = None
              
              while True:
                  params['page'] = str(page)
                  
                  try:
                      response = requests.get(BASE_URL, params=params, headers=HEADERS, timeout=30)
                      
                      if response.status_code == 200:
                          data = response.json()
                          
                          if total_pages is None:
                              total_pages = data.get('pages', 0)
                              total_found = data.get('found', 0)
                              print(f"   –ù–∞–π–¥–µ–Ω–æ: {total_found} –≤–∞–∫–∞–Ω—Å–∏–π ({total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü)")
                          
                          items = data.get('items', [])
                          all_vacancies.extend(items)
                          
                          page += 1
                          if page >= total_pages:
                              break
                          
                          time.sleep(REQUEST_DELAY)
                      else:
                          print(f"   ‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                          break
                          
                  except Exception as e:
                      print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
                      break
              
              print(f"   ‚úÖ –°–æ–±—Ä–∞–Ω–æ: {len(all_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π")
              return all_vacancies
          
          
          def clean_html(html_text: str) -> str:
              """–û—á–∏—â–∞–µ—Ç HTML —Ç–µ–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
              if not html_text:
                  return ""
              clean = re.sub('<.*?>', '', html_text)
              clean = clean.replace('&nbsp;', ' ').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
              clean = ' '.join(clean.split())
              return clean
          
          
          def format_salary(salary_data: Dict) -> str:
              """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞—Ä–ø–ª–∞—Ç–µ"""
              if not salary_data:
                  return "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
              
              try:
                  salary_from = salary_data.get('from')
                  salary_to = salary_data.get('to')
                  currency = salary_data.get('currency', 'RUR')
                  gross = salary_data.get('gross', False)
                  
                  if salary_from:
                      salary_from = f"{salary_from:,}".replace(',', ' ')
                  if salary_to:
                      salary_to = f"{salary_to:,}".replace(',', ' ')
                  
                  if salary_from and salary_to:
                      result = f"{salary_from} - {salary_to} {currency}"
                  elif salary_from:
                      result = f"–æ—Ç {salary_from} {currency}"
                  elif salary_to:
                      result = f"–¥–æ {salary_to} {currency}"
                  else:
                      return "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
                  
                  if gross:
                      result += " –¥–æ –≤—ã—á–µ—Ç–∞ –Ω–∞–ª–æ–≥–æ–≤"
                  else:
                      result += " –Ω–∞ —Ä—É–∫–∏"
                  
                  return result
              except Exception:
                  return "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
          
          
          def safe_get(data: Optional[Dict], *keys) -> any:
              """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
              if data is None:
                  return None
              result = data
              for key in keys:
                  if isinstance(result, dict):
                      result = result.get(key)
                      if result is None:
                          return None
                  else:
                      return None
              return result
          
          
          def parse_vacancy(item: Dict) -> Dict:
              """–ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
              try:
                  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ
                  employer = item.get('employer') or {}
                  
                  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ª–æ–≥–æ—Ç–∏–ø–∞
                  logo_urls = employer.get('logo_urls') or {}
                  company_logo = logo_urls.get('original', '')
                  
                  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥—Ä—É–≥–∏—Ö –ø–æ–ª–µ–π
                  vacancy = {
                      'id': item.get('id', ''),
                      'name': item.get('name', ''),
                      'company': employer.get('name', ''),
                      'company_id': employer.get('id', ''),
                      'company_url': employer.get('alternate_url', ''),
                      'company_logo': company_logo,
                      'url': item.get('alternate_url', ''),
                      'published_at': item.get('published_at', ''),
                      'created_at': item.get('created_at', ''),
                      'area': safe_get(item, 'area', 'name') or '',
                      'salary': format_salary(item.get('salary')),
                      'salary_raw': item.get('salary'),
                      'experience': safe_get(item, 'experience', 'name') or '',
                      'schedule': safe_get(item, 'schedule', 'name') or '',
                      'employment': safe_get(item, 'employment', 'name') or '',
                      'requirement': clean_html(safe_get(item, 'snippet', 'requirement') or ''),
                      'responsibility': clean_html(safe_get(item, 'snippet', 'responsibility') or ''),
                      'type': safe_get(item, 'type', 'name') or '',
                      'professional_roles': [],
                      'has_test': item.get('has_test', False),
                      'premium': item.get('premium', False),
                      'accept_handicapped': item.get('accept_handicapped', False),
                      'accept_kids': item.get('accept_kids', False),
                      'accept_temporary': item.get('accept_temporary', False)
                  }
                  
                  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–æ–ª–µ–π
                  roles = item.get('professional_roles', [])
                  if isinstance(roles, list):
                      vacancy['professional_roles'] = [role.get('name', '') for role in roles if isinstance(role, dict)]
                  
                  return vacancy
                  
              except Exception as e:
                  print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                  return {
                      'id': item.get('id', ''),
                      'name': item.get('name', '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏'),
                      'company': '',
                      'company_id': '',
                      'company_url': '',
                      'company_logo': '',
                      'url': item.get('alternate_url', ''),
                      'published_at': item.get('published_at', ''),
                      'created_at': '',
                      'area': '',
                      'salary': '–Ω–µ —É–∫–∞–∑–∞–Ω–∞',
                      'salary_raw': None,
                      'experience': '',
                      'schedule': '',
                      'employment': '',
                      'requirement': '',
                      'responsibility': '',
                      'type': '',
                      'professional_roles': [],
                      'has_test': False,
                      'premium': False,
                      'accept_handicapped': False,
                      'accept_kids': False,
                      'accept_temporary': False
                  }
          
          
          def collect_all_vacancies() -> List[Dict]:
              """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –≤—Å–µ–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
              print("=== –°–ë–û–† –í–°–ï–• –í–ê–ö–ê–ù–°–ò–ô –ü–û –°–ò–°–¢–ï–ú–ù–û–ú–£ –ê–î–ú–ò–ù–ò–°–¢–†–ò–†–û–í–ê–ù–ò–Æ ===")
              print(f"–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: {datetime.now()}")
              print(f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞: {', '.join(SEARCH_KEYWORDS)}")
              
              unique_vacancy_ids: Set[str] = set()
              all_vacancies: List[Dict] = []
              
              for keyword in SEARCH_KEYWORDS:
                  vacancies = get_vacancies_by_keyword(keyword)
                  
                  new_count = 0
                  for item in vacancies:
                      try:
                          vacancy_id = item.get('id')
                          if vacancy_id and vacancy_id not in unique_vacancy_ids:
                              unique_vacancy_ids.add(vacancy_id)
                              vacancy = parse_vacancy(item)
                              all_vacancies.append(vacancy)
                              new_count += 1
                              
                              if len(all_vacancies) % 25 == 0:
                                  print(f"   üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(all_vacancies)}")
                      except Exception as e:
                          print(f"   ‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—è –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {e}")
                          continue
                  
                  print(f"   üìå –ù–æ–≤—ã—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {new_count}")
              
              # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
              try:
                  all_vacancies.sort(key=lambda x: x.get('published_at', ''), reverse=True)
              except Exception as e:
                  print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
              
              return all_vacancies
          
          
          def save_vacancies(vacancies: List[Dict], filename: str = 'hh_vacancies.json'):
              """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ JSON —Ñ–∞–π–ª"""
              stats = {
                  'total': len(vacancies),
                  'with_salary': sum(1 for v in vacancies if v.get('salary', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞') != '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
                  'companies': len(set(v.get('company', '') for v in vacancies if v.get('company'))),
                  'cities': len(set(v.get('area', '') for v in vacancies if v.get('area'))),
                  'premium': sum(1 for v in vacancies if v.get('premium', False)),
                  'with_test': sum(1 for v in vacancies if v.get('has_test', False))
              }
              
              output = {
                  'source': 'hh.ru',
                  'search_keywords': SEARCH_KEYWORDS,
                  'search_params': {
                      'area': '–†–æ—Å—Å–∏—è',
                      'schedule': '–£–¥–∞–ª—ë–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞',
                      'search_field': '–í –Ω–∞–∑–≤–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏'
                  },
                  'updated': datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'),
                  'statistics': stats,
                  'vacancies': vacancies
              }
              
              # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª
              if os.path.exists(filename):
                  os.remove(filename)
                  print(f"   üóëÔ∏è –°—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω")
              
              with open(filename, 'w', encoding='utf-8') as f:
                  json.dump(output, f, ensure_ascii=False, indent=2)
              
              print(f"\n‚úÖ –§–∞–π–ª {filename} —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
              print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
              for key, value in stats.items():
                  print(f"   - {key}: {value}")
          
          
          def main():
              """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
              try:
                  vacancies = collect_all_vacancies()
                  
                  if not vacancies:
                      print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–∏ –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏")
                      # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫
                      empty_output = {
                          'source': 'hh.ru',
                          'search_keywords': SEARCH_KEYWORDS,
                          'search_params': {
                              'area': '–†–æ—Å—Å–∏—è',
                              'schedule': '–£–¥–∞–ª—ë–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞',
                              'search_field': '–í –Ω–∞–∑–≤–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏'
                          },
                          'updated': datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'),
                          'statistics': {
                              'total': 0,
                              'with_salary': 0,
                              'companies': 0,
                              'cities': 0,
                              'premium': 0,
                              'with_test': 0
                          },
                          'vacancies': []
                      }
                      with open('hh_vacancies.json', 'w', encoding='utf-8') as f:
                          json.dump(empty_output, f, ensure_ascii=False, indent=2)
                      return False
                  
                  save_vacancies(vacancies)
                  
                  # –¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–π —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
                  try:
                      companies = {}
                      for v in vacancies:
                          company = v.get('company', '')
                          if company:
                              companies[company] = companies.get(company, 0) + 1
                      
                      if companies:
                          top_companies = sorted(companies.items(), key=lambda x: x[1], reverse=True)[:5]
                          print("\nüè¢ –¢–æ–ø-5 –∫–æ–º–ø–∞–Ω–∏–π:")
                          for company, count in top_companies:
                              print(f"   - {company}: {count} –≤–∞–∫–∞–Ω—Å–∏–π")
                  except Exception as e:
                      print(f"\n‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–≤–µ—Å—Ç–∏ —Ç–æ–ø –∫–æ–º–ø–∞–Ω–∏–π: {e}")
                  
                  print("\n‚ú® –ì–æ—Ç–æ–≤–æ!")
                  return True
                  
              except Exception as e:
                  print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
                  import traceback
                  traceback.print_exc()
                  
                  # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –æ—à–∏–±–∫–æ–π
                  error_output = {
                      'source': 'hh.ru',
                      'error': str(e),
                      'updated': datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'),
                      'vacancies': []
                  }
                  with open('hh_vacancies.json', 'w', encoding='utf-8') as f:
                      json.dump(error_output, f, ensure_ascii=False, indent=2)
                  
                  return False
          
          
          if __name__ == "__main__":
              success = main()
              exit(0 if success else 1)
          EOF
          
      - name: Collect vacancies
        run: |
          echo "=== –°—Ç–∞—Ä—Ç —Å–±–æ—Ä–∞ –≤–∞–∫–∞–Ω—Å–∏–π ==="
          python collect_vacancies.py || echo "–°–∫—Ä–∏–ø—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º"
          
      - name: Verify results
        run: |
          echo ""
          echo "=== –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ==="
          if [ -f "hh_vacancies.json" ]; then
            FILE_SIZE=$(stat -f%z "hh_vacancies.json" 2>/dev/null || stat -c%s "hh_vacancies.json")
            VACANCY_COUNT=$(grep -o '"id"' hh_vacancies.json | wc -l || echo "0")
            echo "‚úÖ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω"
            echo "üìÅ –†–∞–∑–º–µ—Ä: $FILE_SIZE –±–∞–π—Ç"
            echo "üìä –í–∞–∫–∞–Ω—Å–∏–π: $VACANCY_COUNT"
            
            if [ "$VACANCY_COUNT" -gt 0 ]; then
              echo ""
              echo "üîç –ü—Ä–∏–º–µ—Ä—ã –≤–∞–∫–∞–Ω—Å–∏–π:"
              grep -A1 '"name"' hh_vacancies.json | head -10 || echo "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã"
            fi
          else
            echo "‚ùå –§–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω!"
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
            echo '{"source":"hh.ru","vacancies":[],"updated":"'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}' > hh_vacancies.json
          fi
          
      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          git add hh_vacancies.json
          
          if git diff --staged --quiet; then
            echo "‚ö†Ô∏è –ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –∫–æ–º–º–∏—Ç–∞"
          else
            VACANCY_COUNT=$(grep -o '"id"' hh_vacancies.json | wc -l || echo "0")
            git commit -m "üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π: –Ω–∞–π–¥–µ–Ω–æ $VACANCY_COUNT –≤–∞–∫–∞–Ω—Å–∏–π [$(date '+%Y-%m-%d %H:%M')]"
            git push
          fi
          
      - name: Deploy to FTP
        if: always()  # –í—Å–µ–≥–¥–∞ –¥–µ–ø–ª–æ–∏–º, –¥–∞–∂–µ –µ—Å–ª–∏ –±—ã–ª–∏ –æ—à–∏–±–∫–∏
        uses: SamKirkland/FTP-Deploy-Action@v4.3.5
        with:
          server: ${{ secrets.FTP_SERVER }}
          username: ${{ secrets.FTP_USERNAME }}
          password: ${{ secrets.FTP_PASSWORD }}
          protocol: ftp
          port: 21
          local-dir: "./"
          server-dir: "www/Vacancy/"
          state-name: ".ftp-deploy-sync-state.json"
          dry-run: false
          log-level: standard
          exclude: |
            **/.git*
            **/.git*/**
            **/node_modules/**
            **/.github/**
            **/README.md
            **/*.py
            **/.ftp-deploy-sync-state.json
