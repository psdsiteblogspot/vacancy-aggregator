name: Update Vacancies Moscow

on:
  schedule:
    - cron: '0 * * * *' # –ó–∞–ø—É—Å–∫ –∫–∞–∂–¥—ã–π —á–∞—Å
  workflow_dispatch: # –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫

jobs:
  update-vacancies:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests
          
      - name: Create vacancy collector script
        run: |
          cat > collect_vacancies.py << 'EOF'
          import requests
          import json
          import time
          from datetime import datetime
          from typing import List, Dict, Optional, Set
          import os
          
          # API HH.ru
          BASE_URL = "https://api.hh.ru/vacancies"
          
          # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
          HEADERS = {
              'User-Agent': 'VacancyAggregator/2.0 (https://gradelift.ru)'
          }
          
          # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
          REQUEST_DELAY = 0.3
          
          # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
          SEARCH_KEYWORDS = [
              '—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä',
              '—Å–∏—Å–∞–¥–º–∏–Ω',
              'system administrator'
          ]
          
          
          def get_vacancies_by_keyword(keyword: str) -> tuple[List[Dict], Dict]:
              """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É –≤ –ú–æ—Å–∫–≤–µ"""
              print(f"\n{'='*60}")
              print(f"üîç –ü–æ–∏—Å–∫: '{keyword}' –≤ –ú–æ—Å–∫–≤–µ")
              print(f"{'='*60}")
              
              params = {
                  'text': keyword,
                  'area': '1',  # –¢–æ–ª—å–∫–æ –ú–æ—Å–∫–≤–∞
                  'search_field': 'name',  # –ò—Å–∫–∞—Ç—å –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
                  'per_page': '100',  # –ú–∞–∫—Å–∏–º—É–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
                  'page': '0'
              }
              
              all_vacancies = []
              page = 0
              stats = {
                  'found': 0,
                  'pages': 0,
                  'collected': 0
              }
              
              while True:
                  params['page'] = str(page)
                  
                  try:
                      response = requests.get(BASE_URL, params=params, headers=HEADERS, timeout=30)
                      
                      if response.status_code == 200:
                          data = response.json()
                          
                          if page == 0:
                              stats['found'] = data.get('found', 0)
                              stats['pages'] = data.get('pages', 0)
                              print(f"–ù–∞–π–¥–µ–Ω–æ: {stats['found']} –≤–∞–∫–∞–Ω—Å–∏–π ({stats['pages']} —Å—Ç—Ä–∞–Ω–∏—Ü)")
                              
                              if stats['found'] > 2000:
                                  print(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ù–∞–π–¥–µ–Ω–æ {stats['found']}, –Ω–æ API –≤–µ—Ä–Ω–µ—Ç –º–∞–∫—Å–∏–º—É–º 2000!")
                          
                          items = data.get('items', [])
                          if not items:
                              print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –ø—É—Å—Ç–∞—è")
                              break
                              
                          all_vacancies.extend(items)
                          print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –ø–æ–ª—É—á–µ–Ω–æ {len(items)} –≤–∞–∫–∞–Ω—Å–∏–π (–≤—Å–µ–≥–æ: {len(all_vacancies)})")
                          
                          page += 1
                          if page >= stats['pages']:
                              break
                          
                          # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ API
                          if len(all_vacancies) >= 2000:
                              print("‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç API –≤ 2000 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                              break
                          
                          time.sleep(REQUEST_DELAY)
                      else:
                          print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                          break
                          
                  except Exception as e:
                      print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
                      break
              
              stats['collected'] = len(all_vacancies)
              print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ: {stats['collected']} –∏–∑ {stats['found']} –≤–∞–∫–∞–Ω—Å–∏–π")
              
              return all_vacancies, stats
          
          
          def parse_vacancy(item: Dict) -> Dict:
              """–ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏"""
              try:
                  employer = item.get('employer') or {}
                  logo_urls = employer.get('logo_urls') or {}
                  
                  vacancy = {
                      'id': item.get('id', ''),
                      'name': item.get('name', ''),
                      'company': employer.get('name', ''),
                      'company_id': employer.get('id', ''),
                      'company_url': employer.get('alternate_url', ''),
                      'company_logo': logo_urls.get('original', ''),
                      'url': item.get('alternate_url', ''),
                      'published_at': item.get('published_at', ''),
                      'area': item.get('area', {}).get('name', ''),
                      'salary': format_salary(item.get('salary')),
                      'experience': item.get('experience', {}).get('name', ''),
                      'schedule': item.get('schedule', {}).get('name', ''),
                      'employment': item.get('employment', {}).get('name', ''),
                      'requirement': clean_html(item.get('snippet', {}).get('requirement', '')),
                      'responsibility': clean_html(item.get('snippet', {}).get('responsibility', '')),
                      'has_test': item.get('has_test', False),
                      'premium': item.get('premium', False)
                  }
                  
                  return vacancy
                  
              except Exception as e:
                  print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                  return {
                      'id': item.get('id', ''),
                      'name': item.get('name', '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏'),
                      'error': str(e)
                  }
          
          
          def format_salary(salary_data: Dict) -> str:
              """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞—Ä–ø–ª–∞—Ç–µ"""
              if not salary_data:
                  return "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
              
              try:
                  salary_from = salary_data.get('from')
                  salary_to = salary_data.get('to')
                  currency = salary_data.get('currency', 'RUR')
                  gross = salary_data.get('gross', False)
                  
                  if salary_from:
                      salary_from = f"{salary_from:,}".replace(',', ' ')
                  if salary_to:
                      salary_to = f"{salary_to:,}".replace(',', ' ')
                  
                  if salary_from and salary_to:
                      result = f"{salary_from} - {salary_to} {currency}"
                  elif salary_from:
                      result = f"–æ—Ç {salary_from} {currency}"
                  elif salary_to:
                      result = f"–¥–æ {salary_to} {currency}"
                  else:
                      return "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
                  
                  if gross:
                      result += " –¥–æ –≤—ã—á–µ—Ç–∞ –Ω–∞–ª–æ–≥–æ–≤"
                  else:
                      result += " –Ω–∞ —Ä—É–∫–∏"
                  
                  return result
              except Exception:
                  return "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
          
          
          def clean_html(text: str) -> str:
              """–û—á–∏—â–∞–µ—Ç HTML —Ç–µ–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
              if not text:
                  return ""
              import re
              clean = re.sub('<.*?>', '', text)
              clean = clean.replace('&nbsp;', ' ').replace('&amp;', '&')
              return ' '.join(clean.split())
          
          
          def collect_all_vacancies() -> List[Dict]:
              """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –≤—Å–µ–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
              print("=== –°–ë–û–† –í–ê–ö–ê–ù–°–ò–ô –°–ò–°–¢–ï–ú–ù–´–• –ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–û–†–û–í –í –ú–û–°–ö–í–ï ===")
              print(f"–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: {datetime.now()}")
              print(f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(SEARCH_KEYWORDS)}")
              
              unique_vacancy_ids: Set[str] = set()
              all_vacancies: List[Dict] = []
              
              total_stats = {
                  'total_found': 0,
                  'total_collected': 0,
                  'by_keyword': {}
              }
              
              for keyword in SEARCH_KEYWORDS:
                  vacancies, stats = get_vacancies_by_keyword(keyword)
                  
                  total_stats['by_keyword'][keyword] = stats
                  total_stats['total_found'] += stats['found']
                  
                  new_count = 0
                  for item in vacancies:
                      vacancy_id = item.get('id')
                      if vacancy_id and vacancy_id not in unique_vacancy_ids:
                          unique_vacancy_ids.add(vacancy_id)
                          vacancy = parse_vacancy(item)
                          all_vacancies.append(vacancy)
                          new_count += 1
                  
                  print(f"üìå –î–æ–±–∞–≤–ª–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {new_count}")
                  print(f"üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(all_vacancies)}")
              
              total_stats['total_collected'] = len(all_vacancies)
              
              # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
              print(f"\n{'='*60}")
              print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
              print(f"{'='*60}")
              
              for keyword, stats in total_stats['by_keyword'].items():
                  print(f"'{keyword}': –Ω–∞–π–¥–µ–Ω–æ {stats['found']}, —Å–æ–±—Ä–∞–Ω–æ {stats['collected']}")
              
              print(f"\n–í–°–ï–ì–û —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {total_stats['total_collected']}")
              
              # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
              try:
                  all_vacancies.sort(key=lambda x: x.get('published_at', ''), reverse=True)
              except Exception as e:
                  print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å: {e}")
              
              return all_vacancies
          
          
          def save_vacancies(vacancies: List[Dict], filename: str = 'hh_vacancies.json'):
              """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ JSON —Ñ–∞–π–ª"""
              # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
              stats = {
                  'total': len(vacancies),
                  'with_salary': sum(1 for v in vacancies if v.get('salary', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞') != '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
                  'companies': len(set(v.get('company', '') for v in vacancies if v.get('company'))),
                  'premium': sum(1 for v in vacancies if v.get('premium', False)),
                  'with_test': sum(1 for v in vacancies if v.get('has_test', False))
              }
              
              # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥—Ä–∞—Ñ–∏–∫–∞–º —Ä–∞–±–æ—Ç—ã
              schedules = {}
              for v in vacancies:
                  schedule = v.get('schedule', '–ù–µ —É–∫–∞–∑–∞–Ω')
                  schedules[schedule] = schedules.get(schedule, 0) + 1
              
              output = {
                  'source': 'hh.ru',
                  'search_keywords': SEARCH_KEYWORDS,
                  'search_params': {
                      'area': '–ú–æ—Å–∫–≤–∞',
                      'area_id': '1',
                      'search_field': '–í –Ω–∞–∑–≤–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏',
                      'filter': '–ë–ï–ó –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤'
                  },
                  'updated': datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'),
                  'statistics': stats,
                  'schedule_distribution': schedules,
                  'total_count': len(vacancies),
                  'vacancies': vacancies
              }
              
              # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª
              if os.path.exists(filename):
                  os.remove(filename)
              
              with open(filename, 'w', encoding='utf-8') as f:
                  json.dump(output, f, ensure_ascii=False, indent=2)
              
              print(f"\n‚úÖ –§–∞–π–ª {filename} —Å–æ–∑–¥–∞–Ω!")
              print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
              for key, value in stats.items():
                  print(f"   - {key}: {value}")
              
              print(f"\nüìÖ –ì—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã:")
              for schedule, count in sorted(schedules.items(), key=lambda x: x[1], reverse=True)[:5]:
                  print(f"   - {schedule}: {count}")
          
          
          def main():
              """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
              try:
                  vacancies = collect_all_vacancies()
                  
                  if not vacancies:
                      print("\n‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π")
                      # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
                      empty_output = {
                          'source': 'hh.ru',
                          'search_keywords': SEARCH_KEYWORDS,
                          'search_params': {
                              'area': '–ú–æ—Å–∫–≤–∞',
                              'area_id': '1',
                              'search_field': '–í –Ω–∞–∑–≤–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏'
                          },
                          'updated': datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'),
                          'statistics': {},
                          'vacancies': []
                      }
                      with open('hh_vacancies.json', 'w', encoding='utf-8') as f:
                          json.dump(empty_output, f, ensure_ascii=False, indent=2)
                      return False
                  
                  save_vacancies(vacancies)
                  
                  # –¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–π
                  try:
                      companies = {}
                      for v in vacancies:
                          company = v.get('company', '')
                          if company:
                              companies[company] = companies.get(company, 0) + 1
                      
                      if companies:
                          top_companies = sorted(companies.items(), key=lambda x: x[1], reverse=True)[:5]
                          print("\nüè¢ –¢–æ–ø-5 –∫–æ–º–ø–∞–Ω–∏–π:")
                          for company, count in top_companies:
                              print(f"   - {company}: {count} –≤–∞–∫–∞–Ω—Å–∏–π")
                  except Exception as e:
                      print(f"\n‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≤–æ–¥–µ —Ç–æ–ø–∞: {e}")
                  
                  print("\n‚ú® –ì–æ—Ç–æ–≤–æ!")
                  return True
                  
              except Exception as e:
                  print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
                  import traceback
                  traceback.print_exc()
                  
                  # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –æ—à–∏–±–∫–æ–π
                  error_output = {
                      'source': 'hh.ru',
                      'error': str(e),
                      'updated': datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'),
                      'vacancies': []
                  }
                  with open('hh_vacancies.json', 'w', encoding='utf-8') as f:
                      json.dump(error_output, f, ensure_ascii=False, indent=2)
                  
                  return False
          
          
          if __name__ == "__main__":
              success = main()
              exit(0 if success else 1)
          EOF
          
      - name: Collect vacancies
        run: |
          echo "=== –°—Ç–∞—Ä—Ç —Å–±–æ—Ä–∞ –≤–∞–∫–∞–Ω—Å–∏–π ==="
          python collect_vacancies.py
          
      - name: Verify results
        run: |
          echo ""
          echo "=== –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ==="
          if [ -f "hh_vacancies.json" ]; then
            FILE_SIZE=$(stat -f%z "hh_vacancies.json" 2>/dev/null || stat -c%s "hh_vacancies.json")
            VACANCY_COUNT=$(grep -o '"id"' hh_vacancies.json | wc -l || echo "0")
            echo "‚úÖ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω"
            echo "üìÅ –†–∞–∑–º–µ—Ä: $FILE_SIZE –±–∞–π—Ç"
            echo "üìä –í–∞–∫–∞–Ω—Å–∏–π: $VACANCY_COUNT"
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≥—Ä–∞—Ñ–∏–∫–∞–º —Ä–∞–±–æ—Ç—ã
            echo ""
            echo "üìÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ä–∞–±–æ—Ç—ã:"
            grep -o '"schedule":[^,]*' hh_vacancies.json | sort | uniq -c | head -10 || echo "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"
          else
            echo "‚ùå –§–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω!"
            echo '{"source":"hh.ru","vacancies":[],"updated":"'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}' > hh_vacancies.json
          fi
          
      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          git add hh_vacancies.json
          
          if git diff --staged --quiet; then
            echo "‚ö†Ô∏è –ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –∫–æ–º–º–∏—Ç–∞"
          else
            VACANCY_COUNT=$(grep -o '"id"' hh_vacancies.json | wc -l || echo "0")
            COMMIT_MSG="üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π –ú–æ—Å–∫–≤–∞: $VACANCY_COUNT –≤–∞–∫–∞–Ω—Å–∏–π [$(date '+%Y-%m-%d %H:%M')]"
            git commit -m "$COMMIT_MSG"
            git push
          fi
          
      - name: Deploy to FTP
        if: always()
        uses: SamKirkland/FTP-Deploy-Action@v4.3.5
        with:
          server: ${{ secrets.FTP_SERVER }}
          username: ${{ secrets.FTP_USERNAME }}
          password: ${{ secrets.FTP_PASSWORD }}
          protocol: ftp
          port: 21
          local-dir: "./"
          server-dir: "www/Vacancy/"
          state-name: ".ftp-deploy-sync-state.json"
          dry-run: false
          log-level: standard
          exclude: |
            **/.git*
            **/.git*/**
            **/node_modules/**
            **/.github/**
            **/README.md
            **/*.py
            **/.ftp-deploy-sync-state.json
